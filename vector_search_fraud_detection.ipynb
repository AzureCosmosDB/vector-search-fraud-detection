{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "from datetime import datetime, timedelta\n",
    "from pymongo import MongoClient\n",
    "from azure.core.exceptions import AzureError\n",
    "from azure.core.credentials import AzureKeyCredential\n",
    "import json\n",
    "import urllib \n",
    "from openai import AzureOpenAI\n",
    "from dotenv import dotenv_values\n",
    "import os\n",
    "config = dotenv_values()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(\"variable.env\", override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import quote_plus\n",
    "\n",
    "MONGO_CONNECTION_STRING= os.getenv(\"MONGO_CONNECTION_STRING\", \"<YOUR-COSMOS-DB-CONNECTION-STRING>\")\n",
    "AOAI_KEY = os.getenv(\"AOAI_KEY\")\n",
    "AOAI_ENDPOINT =  os.getenv(\"AOAI_ENDPOINT\")\n",
    "API_VERSION =  os.getenv(\"API_VERSION\")\n",
    "AOAI_EMBEDDING_DEPLOYMENT =  os.getenv(\"AOAI_EMBEDDING_DEPLOYMENT\")\n",
    "AOAI_EMBEDDING_DEPLOYMENT_MODEL =  os.getenv(\"AOAI_EMBEDDING_DEPLOYMENT_MODEL\")\n",
    "\n",
    "\n",
    "client = AzureOpenAI(\n",
    "  azure_endpoint= AOAI_ENDPOINT,\n",
    "  api_key=AOAI_KEY,  \n",
    "  api_version=API_VERSION\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embedding(text):\n",
    "    response = client.embeddings.create(\n",
    "        model=AOAI_EMBEDDING_DEPLOYMENT_MODEL,\n",
    "        input=text\n",
    "    )\n",
    "    return response.data[0].embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mongo_conn = MONGO_CONNECTION_STRING\n",
    "mongo_client = MongoClient(mongo_conn)\n",
    "\n",
    "db = mongo_client['account']\n",
    "\n",
    "# Create collection if it doesn't exist\n",
    "COLLECTION_NAME = \"transactions\"\n",
    "\n",
    "collection = db[COLLECTION_NAME]\n",
    "\n",
    "if COLLECTION_NAME not in db.list_collection_names():\n",
    "    db.create_collection(COLLECTION_NAME)\n",
    "    print(\"Created collection '{}'.\\n\".format(COLLECTION_NAME))\n",
    "else:\n",
    "    print(\"Using collection: '{}'.\\n\".format(COLLECTION_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load JSON data from file\n",
    "with open(\"test.json\", 'r') as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Remove _id field from each item\n",
    "data = [{k: v for k, v in item.items() if k != '_id'} for item in data]\n",
    "\n",
    "df = pd.DataFrame(data, columns= [\"TransactionID\",\n",
    "        \"Amount\",\n",
    "        \"Timestamp\",\n",
    "        \"Location\",\n",
    "        \"Merchant\",\n",
    "        \"Fraud\"])\n",
    "# Print the cleaned data\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "# List to store embeddings along with transaction details\n",
    "embeddings = []\n",
    "\n",
    "# Loop through each record in the JSON data and generate embeddings\n",
    "for index, row in df.iterrows():\n",
    "    # Combine relevant fields into a single text input for embedding generation\n",
    "    text = f\"TransactionID: {row['TransactionID']}, Amount: {row['Amount']}, Timestamp: {row['Timestamp']}, Location: {row['Location']}, Merchant: {row['Merchant']}\"\n",
    "    \n",
    "    # Generate embedding based on the text\n",
    "    embedding = generate_embedding(text)\n",
    "    \n",
    "    # Append the result (transaction + embedding) to the embeddings list\n",
    "    embeddings.append({\n",
    "        \"TransactionID\": row[\"TransactionID\"],\n",
    "        \"Amount\": row[\"Amount\"],\n",
    "        \"Timestamp\": str(row[\"Timestamp\"]),  # Convert Timestamp to string for consistency\n",
    "        \"Location\": row[\"Location\"],\n",
    "        \"Merchant\": row[\"Merchant\"],\n",
    "        \"Fraud\": row[\"Fraud\"],\n",
    "        \"Embedding\": embedding\n",
    "    })\n",
    "    \n",
    "with open(\"transactions_with_embeddings.json\", \"w\") as f:\n",
    "    json.dump(embeddings, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.command({\n",
    "  'createIndexes': 'transactions',\n",
    "  'indexes': [\n",
    "    {\n",
    "      'name': 'transactionsIndex',\n",
    "      'key': {\n",
    "        \"Embedding\": \"cosmosSearch\"\n",
    "      },\n",
    "      'cosmosSearchOptions': {\n",
    "        'kind': 'vector-hnsw',\n",
    "        'numLists': 1,\n",
    "        'similarity': 'Euclidean',\n",
    "        'dimensions': 1536\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db.command({'dropIndexes': 'transactions', 'index': 'transactionsIndex'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "collection.delete_many({})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('transactions_with_embeddings.json') as file:\n",
    "    file_data = json.load(file)\n",
    "collection.insert_many(file_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search(new_transaction, num_results=5):\n",
    "    # Generate the embedding for the new transaction\n",
    "    query_embedding = generate_embedding(new_transaction)\n",
    "\n",
    "    # Define the search pipeline with vector search using the `Embedding` field\n",
    "    pipeline = [\n",
    "        {\n",
    "            '$search': {\n",
    "                \"cosmosSearch\": {\n",
    "                    \"vector\": query_embedding,  # The query vector (embedding of the new transaction)\n",
    "                    \"path\": \"Embedding\",  # The field that contains embeddings in the collection\n",
    "                    \"k\": num_results,  # Number of results to return\n",
    "                    \"efSearch\": 10,\n",
    "                #    \"filter\": {\"Fraud\": {\"neq\": \"False\"}}\n",
    "                },\n",
    "                \"returnStoredSource\": False\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$project': {\n",
    "                'similarityScore': { '$meta': 'searchScore' },  # Project the similarity score\n",
    "                'TransactionID': 1, \n",
    "                'Amount': 1,\n",
    "                'Timestamp': 1,\n",
    "                'Location': 1,\n",
    "                'Merchant': 1,\n",
    "                'Fraud': 1\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Execute the aggregation pipeline in Cosmos DB\n",
    "    results = collection.aggregate(pipeline)\n",
    "    \n",
    "    \n",
    "    return results\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example new transaction (replace with actual transaction data)\n",
    "new_transaction = {\n",
    "    \"TransactionID\": \"T5978\",\n",
    "    \"Amount\": 15.00, # where clause \n",
    "    \"Timestamp\": \"2024-09-15 14:30:00\", # where clause \n",
    "    \"Location\": \"Boston\", # coordinates and use eucliead distance \n",
    "    \"Merchant\": \"Walmart\" \n",
    "}\n",
    "\n",
    "new_transaction_text=f\"TransactionID: {new_transaction['TransactionID']}, Timestamp: {new_transaction['Timestamp']}, Location: {new_transaction['Location']}, Merchant{new_transaction['Merchant']}\"\n",
    "\n",
    "## where clauses - for amount/ location \n",
    "# Perform the vector search and get the top 5 most similar fraudulent transactions\n",
    "results = vector_search(new_transaction_text, num_results=5)\n",
    "# Output results\n",
    "for r in results:\n",
    "    print(r) \n",
    "print(f\"TransactionID: {new_transaction['TransactionID']}, Location: {new_transaction['Location']}, Merchant: {new_transaction['Merchant']}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a geo/spatial index on the \"LocationCoordinates\" field\n",
    "db.command({\n",
    "  'createIndexes': COLLECTION_NAME,\n",
    "  'indexes': [\n",
    "    {\n",
    "      'name': 'locationGeoIndex',\n",
    "      'key': {\n",
    "        'LocationCoordinates': '2dsphere'\n",
    "      }\n",
    "    }\n",
    "  ]\n",
    "})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO\n",
    "def get_location_coordinates(location):\n",
    "    location_map = {\n",
    "        \"Boston\": [42.3601, -71.0589],\n",
    "        \"New York\": [40.7128, -74.0060],\n",
    "        \"San Francisco\": [37.7749, -122.4194]\n",
    "    }\n",
    "    return location_map.get(location, [0, 0])  # Default to [0, 0] if location not found\n",
    "\n",
    "# Add the coordinates to the embedding data\n",
    "for index, row in df.iterrows():\n",
    "    text = f\"TransactionID: {row['TransactionID']}, Amount: {row['Amount']}, Timestamp: {row['Timestamp']}, Location: {row['Location']}, Merchant: {row['Merchant']}\"\n",
    "    embedding = generate_embedding(text)\n",
    "\n",
    "    # Get location coordinates\n",
    "    location_coordinates = get_location_coordinates(row['Location'])\n",
    "\n",
    "    embeddings.append({\n",
    "        \"TransactionID\": row[\"TransactionID\"],\n",
    "        \"Amount\": row[\"Amount\"],\n",
    "        \"Timestamp\": str(row[\"Timestamp\"]),\n",
    "        \"Location\": row[\"Location\"],\n",
    "        \"LocationCoordinates\": {\n",
    "            \"type\": \"Point\",\n",
    "            \"coordinates\": location_coordinates  # Add geo-coordinates to the document\n",
    "        },\n",
    "        \"Merchant\": row[\"Merchant\"],\n",
    "        \"Fraud\": row[\"Fraud\"],\n",
    "        \"Embedding\": embedding\n",
    "    })\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search_with_st_distance(new_transaction, num_results=5):\n",
    "    # Generate the embedding for the new transaction\n",
    "    query_embedding = generate_embedding(new_transaction[\"text\"])\n",
    "\n",
    "    # Get location coordinates for the new transaction\n",
    "    new_transaction_coordinates = get_location_coordinates(new_transaction[\"Location\"])\n",
    "\n",
    "    # Define the pipeline with vector search and distance filtering using ST_DISTANCE\n",
    "    pipeline = [\n",
    "        {\n",
    "            '$search': {\n",
    "                \"cosmosSearch\": {\n",
    "                    \"vector\": query_embedding,\n",
    "                    \"path\": \"Embedding\",  # The field that contains embeddings\n",
    "                    \"k\": num_results,  # Number of results to return\n",
    "                    \"efSearch\": 10\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$match': {\n",
    "                # Add WHERE clause using ST_DISTANCE for the distance between coordinates\n",
    "                '$expr': {\n",
    "                    '$lt': [\n",
    "                        {'$function': {\n",
    "                            'body': 'ST_DISTANCE',\n",
    "                            'args': [\n",
    "                                {\"type\": \"Point\", \"coordinates\": new_transaction_coordinates}, \n",
    "                                '$LocationCoordinates'  # Location of the existing transaction\n",
    "                            ],\n",
    "                        }},\n",
    "                        50000  # 50 km radius, adjust as needed\n",
    "                    ]\n",
    "                },\n",
    "                # WHERE clause for Amount (50% to 200% of the new transaction amount)\n",
    "                'Amount': {\n",
    "                    '$gte': new_transaction['Amount'] * 0.5,\n",
    "                    '$lte': new_transaction['Amount'] * 2.0\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$project': {\n",
    "                'similarityScore': { '$meta': 'searchScore' },  # Vector search similarity score\n",
    "                'TransactionID': 1,\n",
    "                'Amount': 1,\n",
    "                'Timestamp': 1,\n",
    "                'Location': 1,\n",
    "                'LocationCoordinates': 1,\n",
    "                'Merchant': 1,\n",
    "                'Fraud': 1\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    # Execute the aggregation pipeline in Cosmos DB\n",
    "    results = collection.aggregate(pipeline)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_location(user_transactions):\n",
    "    lat_sum = 0\n",
    "    lon_sum = 0\n",
    "    count = len(user_transactions)+1\n",
    "    \n",
    "    for txn in user_transactions:\n",
    "        coordinates = txn['LocationCoordinates']['coordinates']\n",
    "        lat_sum += coordinates[0]\n",
    "        lon_sum += coordinates[1]\n",
    "    \n",
    "    avg_lat = lat_sum / count\n",
    "    avg_lon = lon_sum / count\n",
    "    return [avg_lat, avg_lon]\n",
    "\n",
    "# Example usage inside the vector search function\n",
    "def vector_search_with_avg_location(new_transaction, num_results=5):\n",
    "    # Generate the embedding for the new transaction\n",
    "    query_embedding = generate_embedding(new_transaction[\"text\"])\n",
    "\n",
    "    # Get user transactions (replace with actual query)\n",
    "    user_transactions = list(collection.find({\"user_id\": new_transaction['user_id']}).sort(\"Timestamp\", -1).limit(10))\n",
    "    avg_location_coordinates = get_average_location(user_transactions)\n",
    "    \n",
    "    pipeline = [\n",
    "        {\n",
    "            '$search': {\n",
    "                \"cosmosSearch\": {\n",
    "                    \"vector\": query_embedding,\n",
    "                    \"path\": \"Embedding\",\n",
    "                    \"k\": num_results,\n",
    "                    \"efSearch\": 10\n",
    "                }\n",
    "            }\n",
    "        },\n",
    "        {\n",
    "            '$match': {\n",
    "                # ST_DISTANCE from new transaction to average location over the last 10 purchases\n",
    "                'LocationCoordinates': {\n",
    "                    '$near': {\n",
    "                        '$geometry': {\n",
    "                            'type': \"Point\",\n",
    "                            'coordinates': avg_location_coordinates\n",
    "                        },\n",
    "                        '$maxDistance': 50000  # 50 km for example\n",
    "                    }\n",
    "                },\n",
    "                'Amount': {\n",
    "                    '$gte': new_transaction['Amount'] * 0.5,\n",
    "                    '$lte': new_transaction['Amount'] * 2.0\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    ]\n",
    "\n",
    "    results = collection.aggregate(pipeline)\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_transaction = {\n",
    "    \"TransactionID\": \"T5978\",\n",
    "    \"Amount\": 15.00,\n",
    "    \"Timestamp\": \"2024-09-15 14:30:00\",\n",
    "    \"Location\": \"Boston\",\n",
    "    \"Merchant\": \"Walmart\",\n",
    "    \"text\": f\"TransactionID: T5978, Amount: 15.00, Timestamp: 2024-09-15 14:30:00, Location: Boston, Merchant: Walmart\",\n",
    "    \"user_id\": \"user123\"  # Add user_id for calculating average location\n",
    "}\n",
    "\n",
    "# Perform the vector search with ST_DISTANCE\n",
    "results = vector_search_with_st_distance(new_transaction, num_results=5)\n",
    "\n",
    "# Output the results\n",
    "for result in results:\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import urllib.parse\n",
    "\n",
    "address = 'Boston, MA'\n",
    "url = 'https://nominatim.openstreetmap.org/search?q=' + urllib.parse.quote(address) +'&format=json'\n",
    "\n",
    "response = requests.get(url).json()\n",
    "print(response[0][\"lat\"])\n",
    "print(response[0][\"lon\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO currently using location as a primary for vector search\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logic \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample MongoDB logic to detect fraud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pymongo\n",
    "from dotenv import load_dotenv\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from datetime import datetime, timedelta\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Load environment variables from a .env file\n",
    "load_dotenv()\n",
    "\n",
    "# Connect to MongoDB\n",
    "mongo_uri = os.getenv(\"MONGODB_URI\")\n",
    "client = pymongo.MongoClient(mongo_uri)\n",
    "database_name = os.getenv(\"MONGODB_DB\")\n",
    "db = client[database_name]\n",
    "accounts = db['accounts']\n",
    "transactions = db['transactions']\n",
    "\n",
    "# Load Sentence Transformer model for generating embeddings\n",
    "model = SentenceTransformer('sentence-transformers/all-mpnet-base-v2')\n",
    "\n",
    "# Helper Function: Generate Embeddings for Text\n",
    "def get_embedding(text):\n",
    "    embedding = model.encode([text])[0]  # Get the vector representation of the text\n",
    "    return embedding.tolist()  # Convert numpy array to list for MongoDB storage\n",
    "\n",
    "# Helper Function: Fraud Encode (Generates text from transaction details)\n",
    "def fraud_encode(doc, near=1000):\n",
    "    pipeline = [\n",
    "        {'$match': {'originator_id': doc[\"originator_id\"]}},\n",
    "        {'$group': {\n",
    "            '_id': '$originator_id',\n",
    "            'std': {'$stdDevSamp': '$transaction_amount'},\n",
    "            'mdn': {'$median': {'input': '$transaction_amount', 'method': 'approximate'}}\n",
    "        }}\n",
    "    ]\n",
    "    result = list(transactions.aggregate(pipeline))\n",
    "\n",
    "    filter_ = {\n",
    "        'originator_id': doc[\"originator_id\"],\n",
    "        'transaction_date': {'$gte': doc[\"transaction_date\"] - timedelta(hours=1), '$lte': doc[\"transaction_date\"]}\n",
    "    }\n",
    "    recent_transactions = list(transactions.find(filter_, {\"transaction_amount\": 1, \"_id\": 0}))\n",
    "    total_amount = sum(item['transaction_amount'] for item in recent_transactions)\n",
    "    num_recent_transactions = len(recent_transactions)\n",
    "\n",
    "    acc = list(accounts.find({'_id': doc[\"originator_id\"]}))[0]\n",
    "    first_transaction = transactions.count_documents({'originator_id': doc[\"originator_id\"], 'beneficiary_id': doc[\"beneficiary_id\"]})\n",
    "\n",
    "    text = f\"A transaction of ${doc['transaction_amount']} was made by {doc['originator_id']}.\"\n",
    "    if first_transaction == 1:\n",
    "        text += \" This is the first transaction between the originator and beneficiary.\"\n",
    "    if doc[\"transaction_amount\"] > acc[\"transaction-limits\"][\"max-transaction-limit\"]:\n",
    "        text += \" The transaction exceeds the originator's maximum transaction limit.\"\n",
    "    elif doc[\"transaction_amount\"] > result[0][\"mdn\"] + result[0][\"std\"]:\n",
    "        text += f\" The transaction amount is unusually high compared to previous transactions.\"\n",
    "\n",
    "    if num_recent_transactions > 1:\n",
    "        text += f\" There were {num_recent_transactions} transactions within the last hour totaling ${total_amount}.\"\n",
    "    return text\n",
    "\n",
    "# Vector Search Pipeline\n",
    "def vector_search_pipeline(limit, query_vector):\n",
    "    pipeline = [\n",
    "        {\"$vectorSearch\": {\n",
    "            \"index\": \"fraud\",\n",
    "            \"path\": \"fraud_vectors\",\n",
    "            \"limit\": limit,\n",
    "            \"numCandidates\": 10000,\n",
    "            \"queryVector\": query_vector\n",
    "        }},\n",
    "        {\"$project\": {\"test\": \"$fraud\"}},\n",
    "        {\"$group\": {\n",
    "            \"_id\": None,\n",
    "            \"total\": {\"$sum\": \"$test\"}\n",
    "        }}\n",
    "    ]\n",
    "    return pipeline\n",
    "\n",
    "# Function to Detect Fraud for a Given Transaction by its ID\n",
    "def detect_fraud(transaction_id):\n",
    "    doc = transactions.find_one({\"_id\": transaction_id})\n",
    "    \n",
    "    if not doc:\n",
    "        return {\"error\": \"Transaction not found!\"}\n",
    "    \n",
    "    # Ensure that the transaction has a valid date and fraud_vectors\n",
    "    if isinstance(doc[\"transaction_date\"], str):\n",
    "        doc[\"transaction_date\"] = datetime.strptime(doc[\"transaction_date\"], '%Y-%m-%dT%H:%M:%S.%f%z')\n",
    "\n",
    "    if \"fraud_vectors\" not in doc or not doc[\"fraud_vectors\"]:\n",
    "        fraud_text = fraud_encode(doc)\n",
    "        doc[\"fraud_vectors\"] = get_embedding(fraud_text)\n",
    "        transactions.update_one({'_id': doc[\"_id\"]}, {'$set': {\"fraud_vectors\": doc[\"fraud_vectors\"]}})\n",
    "\n",
    "    # Perform vector search for potential fraud detection\n",
    "    limit = 4000  # Example limit for search\n",
    "    fraud_result = list(transactions.aggregate(vector_search_pipeline(limit, doc[\"fraud_vectors\"])))\n",
    "\n",
    "    # Evaluate result based on search results\n",
    "    set_doc = {}\n",
    "    if fraud_result[0][\"total\"] >= np.floor(limit / 2):\n",
    "        set_doc[\"fraud_detected\"] = True\n",
    "    else:\n",
    "        set_doc[\"fraud_detected\"] = False\n",
    "\n",
    "    # Update the transaction document with fraud detection result\n",
    "    transactions.update_one({'_id': doc[\"_id\"]}, {'$set': set_doc})\n",
    "\n",
    "    return set_doc\n",
    "\n",
    "# Example Usage: Detect fraud for a specific transaction by its ID\n",
    "from bson import ObjectId\n",
    "\n",
    "# Replace 'your_transaction_id_here' with an actual ObjectId from your MongoDB\n",
    "transaction_id = ObjectId(\"your_transaction_id_here\")\n",
    "\n",
    "# Detect fraud\n",
    "fraud_detection_result = detect_fraud(transaction_id)\n",
    "print(fraud_detection_result)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
