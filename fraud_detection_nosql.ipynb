{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This project implements a **fraud detection system** that integrates **Azure Cosmos DB** and **Azure OpenAI embeddings**. It allows the detection of suspicious activities based on transaction patterns, geographical information, and vector similarity using embeddings generated by OpenAI's API. The system stores transaction data in Cosmos DB, generates embeddings for the locations, and performs vector-based searches to detect anomalies in transactions.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To set up and run this project, the following Python packages are required:\n",
    "\n",
    "1. **python-dotenv**: For loading environment variables from a `.env` file.\n",
    "2. **openai**: To interact with the OpenAI API for generating embeddings.\n",
    "3. **geopy**: For geocoding city names into latitude and longitude coordinates.\n",
    "4. **azure-cosmos**: For interacting with the Azure Cosmos DB service.\n",
    "\n",
    "You can install these packages by running:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-dotenv\n",
    "! pip install openai\n",
    "! pip install geopy\n",
    "! pip install azure-cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from dotenv import dotenv_values\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "import pandas as pd\n",
    "\n",
    "#Cosmos DB imports\n",
    "from azure.cosmos import CosmosClient, PartitionKey, exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "You need to set up a `.env` file that contains your connection details to Azure Cosmos DB and Azure OpenAI. Here's a template for the environment variables that should be included:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"variable.env\" # following example.env template change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "nosql_uri=config[\"NOSQL_URI\"]\n",
    "cosmos_key = config['NOSQL_PRIMARY_KEY']\n",
    "DATABASE_NAME = \"fraud-nosql-db2\"\n",
    "CONTAINER_NAME = \"fraud-nosql-cont\"\n",
    "openai_endpoint = config['AOAI_ENDPOINT']\n",
    "openai_key = config['AOAI_KEY']\n",
    "openai_api_version = config['API_VERSION']\n",
    "openai_embeddings_deployment = config['AOAI_EMBEDDING_DEPLOYMENT']\n",
    "openai_embeddings_model = config['AOAI_EMBEDDING_DEPLOYMENT_MODEL']\n",
    "\n",
    "cosmos_client = CosmosClient(url=nosql_uri, credential=cosmos_key)\n",
    "\n",
    "azure_openai_embeddings = AzureOpenAI(\n",
    "    api_version=openai_api_version,\n",
    "    api_key= openai_key,\n",
    "    azure_endpoint= openai_endpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db= cosmos_client.create_database_if_not_exists(\n",
    "    id=DATABASE_NAME\n",
    ")\n",
    "properties = db.read()\n",
    "print(json.dumps(properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_embedding_policy = {\n",
    "    \"vectorEmbeddings\": [\n",
    "        {\n",
    "            \"path\":\"/locationVector\",\n",
    "            \"dataType\":\"float32\",\n",
    "            \"distanceFunction\":\"cosine\",\n",
    "            \"dimensions\":1536\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "indexing_policy = {\n",
    "    \"includedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"excludedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/\\\"_etag\\\"/?\"\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/locationVector/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"vectorIndexes\": [\n",
    "        {\"path\": \"/locationVector\",\n",
    "         \"type\": \"diskANN\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    container = db.create_container_if_not_exists(\n",
    "                    id=CONTAINER_NAME,\n",
    "                    partition_key=PartitionKey(path=\"/TenantId\"),\n",
    "                    indexing_policy=indexing_policy,\n",
    "                    vector_embedding_policy=vector_embedding_policy)\n",
    "\n",
    "    properties = container.read()\n",
    "    print('Container with properties \\'{0}\\' created'.format(properties))\n",
    "\n",
    "except exceptions.CosmosResourceExistsError:\n",
    "    print('A container with id \\'{0}\\' already exists'.format(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(lat_lon):\n",
    "    lat_lon_str = f\"{lat_lon[0]},{lat_lon[1]}\"\n",
    "    \n",
    "    # Call OpenAI to generate embeddings (assuming text input is required)\n",
    "    response = azure_openai_embeddings.embeddings.create(input=lat_lon_str, model=openai_embeddings_model)\n",
    "    embeddings = response.model_dump()\n",
    "    \n",
    "    time.sleep(0.5)  # To avoid API rate limits\n",
    "    \n",
    "    return embeddings['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def get_city_coordinates(city_name):\n",
    "    try:\n",
    "        # Create a geolocator object using Nominatim service\n",
    "        geolocator = Nominatim(user_agent=\"MyAPP\")\n",
    "        \n",
    "        # Geocode the city name to get location details\n",
    "        location = geolocator.geocode(city_name)\n",
    "        \n",
    "        if location:\n",
    "            # Extract the latitude and longitude from the location object\n",
    "            lat = location.latitude\n",
    "            lon = location.longitude\n",
    "            return lat, lon\n",
    "        else:\n",
    "            print(f\"City '{city_name}' not found.\")\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load text-sample_w_embeddings.json which has embeddings pre-computed\n",
    "data_file = open(file=\"data/data_with_tenants.json\", mode=\"r\") \n",
    "\n",
    "data = json.load(data_file)\n",
    "data_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Take a peek at one data item\n",
    "print(json.dumps(data[4], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for each location and store data in cosmos db container\n",
    "for item in data:\n",
    "    transaction_id = item[\"TransactionID\"]\n",
    "    item['id'] = transaction_id\n",
    "    location = item[\"Location\"]\n",
    "    location_coord = get_city_coordinates(location)\n",
    "    location_embeddings = generate_embeddings(location_coord)\n",
    "    item['locationVector'] = location_embeddings\n",
    "    item['@search.action'] = 'upload'\n",
    "   \n",
    "    print(\"Creating embeddings for transaction:\", transaction_id, end='\\r')\n",
    "    \n",
    "    # Insert the item into the container\n",
    "    container.upsert_item(item)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_average_location_vector(container, tenant_id):\n",
    "    # SQL query to get the last 'num_purchases' transactions ordered by timestamp\n",
    "    sql_query = \"\"\"\n",
    "    SELECT c.locationVector\n",
    "    FROM c\n",
    "    WHERE c.TenantId = @tenant_id\n",
    "    ORDER BY c.Timestamp DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parameters for the query\n",
    "    parameters = [\n",
    "        {\"name\": \"@tenant_id\", \"value\": tenant_id}\n",
    "    ]\n",
    "    \n",
    "    # Execute the query to get the location vectors\n",
    "    results = container.query_items(\n",
    "        query=sql_query,\n",
    "        parameters=parameters,\n",
    "        enable_cross_partition_query=True\n",
    "    )\n",
    "    \n",
    "    # Collect the location vectors\n",
    "    vectors = []\n",
    "    for result in results:\n",
    "        vectors.append(result['locationVector'])\n",
    "    \n",
    "    \n",
    "    # If no vectors are found, return None\n",
    "    if not vectors:\n",
    "        return None\n",
    "    \n",
    "    # Convert the list of vectors into a numpy array\n",
    "    vectors_np = np.array(vectors)\n",
    "    \n",
    "    # Calculate the element-wise average of the vectors\n",
    "    avg_vector = np.mean(vectors_np, axis=0)\n",
    "    \n",
    "    return avg_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search( current_location_vector, tenant_id, average_location_vector, amount, num_results=5):\n",
    "\n",
    "    if isinstance(current_location_vector, np.ndarray):\n",
    "        current_location_vector = current_location_vector.tolist()\n",
    "    if isinstance(average_location_vector, np.ndarray):\n",
    "        average_location_vector = average_location_vector.tolist()\n",
    "\n",
    "    sql_query = \"\"\"\n",
    " SELECT \n",
    "        c.TransactionID,\n",
    "        c.Amount, \n",
    "        c.Timestamp, \n",
    "        c.Location, \n",
    "        c.Merchant,\n",
    "        c.TenantId, \n",
    "        VectorDistance(c.locationVector, @current_location_vector) AS ProximityOfCurrentToLast,\n",
    "        VectorDistance(@current_location_vector, @average_location_vector) AS ProximityOfAverageToLast\n",
    "    FROM c\n",
    "    WHERE \n",
    "        VectorDistance(c.locationVector, @current_location_vector) > 0.1\n",
    "        AND VectorDistance(@current_location_vector, @average_location_vector) > 0.1\n",
    "        AND c.TenantId = @tenant_id\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameters for the SQL query\n",
    "    parameters = [\n",
    "        {\"name\": \"@num_results\", \"value\": num_results},   \n",
    "        {\"name\": \"@average_location_vector\", \"value\": average_location_vector},  \n",
    "        {\"name\": \"@current_location_vector\", \"value\": current_location_vector},  \n",
    "        {\"name\": \"@amount\", \"value\": amount},  # Transaction amount range filtering\n",
    "        {\"name\": \"@tenant_id\", \"value\": tenant_id},  # Transaction amount range filtering\n",
    "    ]\n",
    "\n",
    "    results = container.query_items(\n",
    "        query=sql_query,\n",
    "        parameters=parameters,\n",
    "        enable_cross_partition_query=True\n",
    "    )\n",
    "\n",
    "    return list(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_search(tenant_id, city, query, amount):\n",
    "\n",
    "    average_location_vector = get_average_location_vector(container, tenant_id)\n",
    "    \n",
    "    # Generate embeddings for the current location\n",
    "    current_location_vector = generate_embeddings(get_city_coordinates(city))\n",
    "    \n",
    "    # Perform vector search\n",
    "    results = vector_search(current_location_vector, tenant_id, average_location_vector, amount, num_results=5)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tenant_id = \"10\"\n",
    "city = \"Sweden\"\n",
    "merchant = \"Walmart\"\n",
    "amount = 1000\n",
    "\n",
    "results = perform_search(tenant_id, city, merchant, amount)\n",
    "print(pd.DataFrame(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
