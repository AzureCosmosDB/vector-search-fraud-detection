{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This project implements a **fraud detection system** that integrates **Azure Cosmos DB** and **Azure OpenAI embeddings**. It allows the detection of suspicious activities based on transaction patterns, geographical information, and vector similarity using embeddings generated by OpenAI's API. The system stores transaction data in Cosmos DB, generates embeddings for the locations, and performs vector-based searches to detect anomalies in transactions.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To set up and run this project, the following Python packages are required:\n",
    "\n",
    "1. **python-dotenv**: For loading environment variables from a `.env` file.\n",
    "2. **openai**: To interact with the OpenAI API for generating embeddings.\n",
    "3. **geopy**: For geocoding city names into latitude and longitude coordinates.\n",
    "4. **azure-cosmos**: For interacting with the Azure Cosmos DB service.\n",
    "\n",
    "You can install these packages by running:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-dotenv\n",
    "! pip install openai\n",
    "! pip install geopy\n",
    "! pip install azure-cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from dotenv import dotenv_values\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Cosmos DB imports\n",
    "from azure.cosmos import CosmosClient, PartitionKey, exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "You need to set up a `.env` file that contains your connection details to Azure Cosmos DB and Azure OpenAI. Here's a template for the environment variables that should be included:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"variable.env\" # following example.env template change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "nosql_uri=config[\"NOSQL_URI\"]\n",
    "cosmos_key = config['NOSQL_PRIMARY_KEY']\n",
    "DATABASE_NAME = \"fraud-nosql-db2\"\n",
    "CONTAINER_NAME = \"fraud-nosql-cont\"\n",
    "openai_endpoint = config['AOAI_ENDPOINT']\n",
    "openai_key = config['AOAI_KEY']\n",
    "openai_api_version = config['API_VERSION']\n",
    "openai_embeddings_deployment = config['AOAI_EMBEDDING_DEPLOYMENT']\n",
    "openai_embeddings_model = config['AOAI_EMBEDDING_DEPLOYMENT_MODEL']\n",
    "\n",
    "cosmos_client = CosmosClient(url=nosql_uri, credential=cosmos_key)\n",
    "\n",
    "azure_openai_embeddings = AzureOpenAI(\n",
    "    api_version=openai_api_version,\n",
    "    api_key= openai_key,\n",
    "    azure_endpoint= openai_endpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"id\": \"fraud-nosql-db2\", \"_rid\": \"+39sAA==\", \"_self\": \"dbs/+39sAA==/\", \"_etag\": \"\\\"0000f401-0000-4700-0000-66ed8ffd0000\\\"\", \"_colls\": \"colls/\", \"_users\": \"users/\", \"_ts\": 1726844925}\n"
     ]
    }
   ],
   "source": [
    "db= cosmos_client.create_database_if_not_exists(\n",
    "    id=DATABASE_NAME\n",
    ")\n",
    "properties = db.read()\n",
    "print(json.dumps(properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_embedding_policy = {\n",
    "    \"vectorEmbeddings\": [\n",
    "        {\n",
    "            \"path\":\"/locationVector\",\n",
    "            \"dataType\":\"float32\",\n",
    "            \"distanceFunction\":\"cosine\",\n",
    "            \"dimensions\":1536\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "indexing_policy = {\n",
    "    \"includedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"excludedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/\\\"_etag\\\"/?\"\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/locationVector/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"vectorIndexes\": [\n",
    "        {\"path\": \"/locationVector\",\n",
    "         \"type\": \"diskANN\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Container with properties '{'id': 'fraud-nosql-cont', 'indexingPolicy': {'indexingMode': 'consistent', 'automatic': True, 'includedPaths': [{'path': '/*'}], 'excludedPaths': [{'path': '/\"_etag\"/?'}, {'path': '/locationVector/*'}], 'vectorIndexes': [{'path': '/locationVector', 'type': 'diskANN'}]}, 'partitionKey': {'paths': ['/TenantId'], 'kind': 'Hash', 'version': 2}, 'conflictResolutionPolicy': {'mode': 'LastWriterWins', 'conflictResolutionPath': '/_ts', 'conflictResolutionProcedure': ''}, 'geospatialConfig': {'type': 'Geography'}, 'vectorEmbeddingPolicy': {'vectorEmbeddings': [{'path': '/locationVector', 'dataType': 'float32', 'dimensions': 1536, 'distanceFunction': 'cosine'}]}, '_rid': '+39sAPLryro=', '_ts': 1726844930, '_self': 'dbs/+39sAA==/colls/+39sAPLryro=/', '_etag': '\"0000f601-0000-4700-0000-66ed90020000\"', '_docs': 'docs/', '_sprocs': 'sprocs/', '_triggers': 'triggers/', '_udfs': 'udfs/', '_conflicts': 'conflicts/'}' created\n"
     ]
    }
   ],
   "source": [
    "try:    \n",
    "    container = db.create_container_if_not_exists(\n",
    "                    id=CONTAINER_NAME,\n",
    "                    partition_key=PartitionKey(path=\"/TenantId\"),\n",
    "                    indexing_policy=indexing_policy,\n",
    "                    vector_embedding_policy=vector_embedding_policy)\n",
    "\n",
    "    properties = container.read()\n",
    "    print('Container with properties \\'{0}\\' created'.format(properties))\n",
    "\n",
    "except exceptions.CosmosResourceExistsError:\n",
    "    print('A container with id \\'{0}\\' already exists'.format(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(lat_lon):\n",
    "    lat_lon_str = f\"{lat_lon[0]},{lat_lon[1]}\"\n",
    "    \n",
    "    response = azure_openai_embeddings.embeddings.create(input=lat_lon_str, model=openai_embeddings_model)\n",
    "    embeddings = response.model_dump()\n",
    "    \n",
    "    time.sleep(0.5)  # To avoid API rate limits\n",
    "    \n",
    "    return embeddings['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def get_city_coordinates(city_name):\n",
    "    try:\n",
    "        # Create a geolocator object using Nominatim service\n",
    "        geolocator = Nominatim(user_agent=\"MyAPP\")\n",
    "        \n",
    "        # Geocode the city name to get location details\n",
    "        location = geolocator.geocode(city_name)\n",
    "        \n",
    "        if location:\n",
    "            # Extract the latitude and longitude from the location object\n",
    "            lat = location.latitude\n",
    "            lon = location.longitude\n",
    "            return lat, lon\n",
    "        else:\n",
    "            print(f\"City '{city_name}' not found.\")\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"TransactionID\": \"T5109\",\n",
      "  \"Amount\": 108.79,\n",
      "  \"Timestamp\": \"2024-09-15 14:02:38\",\n",
      "  \"Location\": \"Boston\",\n",
      "  \"Merchant\": \"Lyft\",\n",
      "  \"Fraud\": false,\n",
      "  \"TenantId\": \"5\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "data_file = open(file=\"data/data_with_tenants.json\", mode=\"r\") \n",
    "\n",
    "data = json.load(data_file)\n",
    "data_file.close()\n",
    "\n",
    "# Take a peek at one data item\n",
    "print(json.dumps(data[4], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating embeddings for transaction: T8612\r"
     ]
    }
   ],
   "source": [
    "# Generate embeddings for each location and store data in cosmos db container\n",
    "for item in data:\n",
    "    transaction_id = item[\"TransactionID\"]\n",
    "    item['id'] = transaction_id\n",
    "    location = item[\"Location\"]\n",
    "    location_coord = get_city_coordinates(location)\n",
    "    location_embeddings = generate_embeddings(location_coord)\n",
    "    item['locationVector'] = location_embeddings\n",
    "    item['@search.action'] = 'upload'\n",
    "   \n",
    "    print(\"Creating embeddings for transaction:\", transaction_id, end='\\r')\n",
    "    \n",
    "    # Insert the item into the container\n",
    "    container.upsert_item(item)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_amount(container, tenant_id):\n",
    "    sql_query = \"SELECT c.Amount FROM c WHERE c.TenantId = @tenant_id\"\n",
    "\n",
    "    # Parameters for the query\n",
    "    parameters = [\n",
    "        {\"name\": \"@tenant_id\", \"value\": tenant_id}\n",
    "    ]\n",
    "    \n",
    "# Execute the query and extract amounts\n",
    "    amounts = []\n",
    "    for item in container.query_items(query=sql_query,parameters=parameters, enable_cross_partition_query=True):\n",
    "        amounts.append(item['Amount'])\n",
    "\n",
    "# Convert the list of amounts to a NumPy array for calculation\n",
    "    amounts_np = np.array(amounts)\n",
    "\n",
    "# Calculate standard deviation\n",
    "    return np.mean(amounts_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_location_vector(container, tenant_id):\n",
    "    # SQL query to get the last 'num_purchases' transactions ordered by timestamp\n",
    "    sql_query = \"\"\"\n",
    "    SELECT c.locationVector\n",
    "    FROM c\n",
    "    WHERE c.TenantId = @tenant_id\n",
    "    ORDER BY c.Timestamp DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parameters for the query\n",
    "    parameters = [\n",
    "        {\"name\": \"@tenant_id\", \"value\": tenant_id}\n",
    "    ]\n",
    "    \n",
    "    # Execute the query to get the location vectors\n",
    "    results = container.query_items(\n",
    "        query=sql_query,\n",
    "        parameters=parameters,\n",
    "        enable_cross_partition_query=True\n",
    "    )\n",
    "    \n",
    "    # Collect the location vectors\n",
    "    vectors = []\n",
    "    for result in results:\n",
    "        vectors.append(result['locationVector'])\n",
    "    \n",
    "    \n",
    "    # If no vectors are found, return None\n",
    "    if not vectors:\n",
    "        return None\n",
    "    \n",
    "    # Convert the list of vectors into a numpy array\n",
    "    vectors_np = np.array(vectors)\n",
    "    \n",
    "    # Calculate the element-wise average of the vectors\n",
    "    avg_vector = np.mean(vectors_np, axis=0)\n",
    "    \n",
    "    return avg_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search( current_location_vector, tenant_id, average_location_vector, amount, num_results=5):\n",
    "\n",
    "    if isinstance(current_location_vector, np.ndarray):\n",
    "        current_location_vector = current_location_vector.tolist()\n",
    "    if isinstance(average_location_vector, np.ndarray):\n",
    "        average_location_vector = average_location_vector.tolist()\n",
    "\n",
    "    sql_query = \"\"\"\n",
    " SELECT \n",
    "        c.TransactionID,\n",
    "        c.Amount, \n",
    "        c.Timestamp, \n",
    "        c.Location, \n",
    "        c.Merchant,\n",
    "        c.TenantId, \n",
    "        VectorDistance(c.locationVector, @current_location_vector) AS LastToCurrDist,\n",
    "        VectorDistance(@current_location_vector, @average_location_vector) AS CurrentToAvgDist\n",
    "    FROM c\n",
    "    WHERE \n",
    "        VectorDistance(c.locationVector, @current_location_vector) > 0.1\n",
    "        AND VectorDistance(@current_location_vector, @average_location_vector) > 0.1\n",
    "        AND c.TenantId = @tenant_id\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameters for the SQL query\n",
    "    parameters = [\n",
    "        {\"name\": \"@num_results\", \"value\": num_results},   \n",
    "        {\"name\": \"@average_location_vector\", \"value\": average_location_vector},  \n",
    "        {\"name\": \"@current_location_vector\", \"value\": current_location_vector},  \n",
    "        {\"name\": \"@amount\", \"value\": amount},  # Transaction amount range filtering\n",
    "        {\"name\": \"@tenant_id\", \"value\": tenant_id},  # Transaction amount range filtering\n",
    "    ]\n",
    "\n",
    "    results = container.query_items(\n",
    "        query=sql_query,\n",
    "        parameters=parameters,\n",
    "        enable_cross_partition_query=True\n",
    "    )\n",
    "\n",
    "    return list(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_search(tenant_id, city, merchant, amount):\n",
    "    try:\n",
    "        # Get mean amount and check if transaction is within reasonable limits\n",
    "        mean_amount = get_mean_amount(container, tenant_id)\n",
    "        if mean_amount is None:\n",
    "            return \"Error: Unable to retrieve the mean transaction amount.\"\n",
    "\n",
    "        if amount >= mean_amount * 3 or amount <= mean_amount * 0.0025:\n",
    "            return \"Alert: Transaction exceeds the mean amount threshold.\"\n",
    "\n",
    "        # Retrieve the average location vector for the tenant\n",
    "        average_location_vector = get_average_location_vector(container, tenant_id)\n",
    "        if average_location_vector is None:\n",
    "            return \"Error: Unable to retrieve the average location vector.\"\n",
    "\n",
    "        # Generate embeddings for the current location\n",
    "        lat_lon = get_city_coordinates(city)\n",
    "        if lat_lon is None or len(lat_lon) != 2:\n",
    "            return f\"Error: Invalid city or unable to retrieve coordinates for '{city}'.\"\n",
    "\n",
    "        current_location_vector = generate_embeddings(lat_lon)\n",
    "        if current_location_vector is None:\n",
    "            return \"Error: Unable to generate location embeddings.\"\n",
    "\n",
    "        # Perform the vector search based on the generated embeddings\n",
    "        results = vector_search(current_location_vector, tenant_id, average_location_vector, amount, num_results=5)\n",
    "        if not results or len(results) == 0:\n",
    "            return \"Error: No results found from the vector search.\"\n",
    "\n",
    "        # Check if there's an anomaly based on proximity distances\n",
    "        if results[0].get(\"CurrentToAvgDist\", 1) < 0.6 or results[0].get(\"LastToCurrDist\", 1) < 0.5:\n",
    "            return \"Alert: This transaction shows irregular behavior based on historical data.\"\n",
    "\n",
    "        # Return the results in a DataFrame if everything is successful\n",
    "        return pd.DataFrame(results)\n",
    "\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred during search: {str(e)}\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transaction exceeds the mean amount threshold.\n"
     ]
    }
   ],
   "source": [
    "tenant_id = \"10\"\n",
    "city = \"China\"\n",
    "merchant = \"Walmart\"\n",
    "amount = 11000\n",
    "\n",
    "results = perform_search(tenant_id, city, merchant, amount)\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
