{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This project implements a **fraud detection system** that integrates **Azure Cosmos DB** and **Azure OpenAI embeddings**. It allows the detection of suspicious activities based on transaction patterns, geographical information, and vector similarity using embeddings generated by OpenAI's API. The system stores transaction data in Cosmos DB, generates embeddings for the locations, and performs vector-based searches to detect anomalies in transactions.\n",
    "\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "To set up and run this project, the following Python packages are required:\n",
    "\n",
    "1. **python-dotenv**: For loading environment variables from a `.env` file.\n",
    "2. **openai**: To interact with the OpenAI API for generating embeddings.\n",
    "3. **geopy**: For geocoding city names into latitude and longitude coordinates.\n",
    "4. **azure-cosmos**: For interacting with the Azure Cosmos DB service.\n",
    "\n",
    "You can install these packages by running:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install python-dotenv\n",
    "! pip install openai\n",
    "! pip install geopy\n",
    "! pip install azure-cosmos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "from dotenv import dotenv_values\n",
    "from openai import OpenAI, AzureOpenAI\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "#Cosmos DB imports\n",
    "from azure.cosmos import CosmosClient, PartitionKey, exceptions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Setup\n",
    "\n",
    "You need to set up a `.env` file that contains your connection details to Azure Cosmos DB and Azure OpenAI. Here's a template for the environment variables that should be included:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "env_name = \"variable.env\" # following example.env template change to your own .env file name\n",
    "config = dotenv_values(env_name)\n",
    "\n",
    "nosql_uri=config[\"NOSQL_URI\"]\n",
    "cosmos_key = config['NOSQL_PRIMARY_KEY']\n",
    "DATABASE_NAME = \"fraud-nosql-db2\"\n",
    "CONTAINER_NAME = \"fraud-nosql-cont\"\n",
    "openai_endpoint = config['AOAI_ENDPOINT']\n",
    "openai_key = config['AOAI_KEY']\n",
    "openai_api_version = config['API_VERSION']\n",
    "openai_embeddings_deployment = config['AOAI_EMBEDDING_DEPLOYMENT']\n",
    "openai_embeddings_model = config['AOAI_EMBEDDING_DEPLOYMENT_MODEL']\n",
    "\n",
    "cosmos_client = CosmosClient(url=nosql_uri, credential=cosmos_key)\n",
    "\n",
    "azure_openai_embeddings = AzureOpenAI(\n",
    "    api_version=openai_api_version,\n",
    "    api_key= openai_key,\n",
    "    azure_endpoint= openai_endpoint,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "db= cosmos_client.create_database_if_not_exists(\n",
    "    id=DATABASE_NAME\n",
    ")\n",
    "properties = db.read()\n",
    "print(json.dumps(properties))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector_embedding_policy = {\n",
    "    \"vectorEmbeddings\": [\n",
    "        {\n",
    "            \"path\":\"/locationVector\",\n",
    "            \"dataType\":\"float32\",\n",
    "            \"distanceFunction\":\"cosine\",\n",
    "            \"dimensions\":1536\n",
    "        },\n",
    "    ]\n",
    "}\n",
    "\n",
    "indexing_policy = {\n",
    "    \"includedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"excludedPaths\": [\n",
    "        {\n",
    "            \"path\": \"/\\\"_etag\\\"/?\"\n",
    "        },\n",
    "        {\n",
    "            \"path\": \"/locationVector/*\"\n",
    "        }\n",
    "    ],\n",
    "    \"vectorIndexes\": [\n",
    "        {\"path\": \"/locationVector\",\n",
    "         \"type\": \"diskANN\"\n",
    "        }\n",
    "    ]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "try:    \n",
    "    container = db.create_container_if_not_exists(\n",
    "                    id=CONTAINER_NAME,\n",
    "                    partition_key=PartitionKey(path=\"/TenantId\"),\n",
    "                    indexing_policy=indexing_policy,\n",
    "                    vector_embedding_policy=vector_embedding_policy)\n",
    "\n",
    "    properties = container.read()\n",
    "    print('Container with properties \\'{0}\\' created'.format(properties))\n",
    "\n",
    "except exceptions.CosmosResourceExistsError:\n",
    "    print('A container with id \\'{0}\\' already exists'.format(id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(lat_lon):\n",
    "    lat_lon_str = f\"{lat_lon[0]},{lat_lon[1]}\"\n",
    "    \n",
    "    response = azure_openai_embeddings.embeddings.create(input=lat_lon_str, model=openai_embeddings_model)\n",
    "    embeddings = response.model_dump()\n",
    "    \n",
    "    time.sleep(0.5)  # To avoid API rate limits\n",
    "    \n",
    "    return embeddings['data'][0]['embedding']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "from geopy.geocoders import Nominatim\n",
    "\n",
    "def get_city_coordinates(city_name):\n",
    "    try:\n",
    "        # Create a geolocator object using Nominatim service\n",
    "        geolocator = Nominatim(user_agent=\"MyAPP\")\n",
    "        \n",
    "        # Geocode the city name to get location details\n",
    "        location = geolocator.geocode(city_name)\n",
    "        \n",
    "        if location:\n",
    "            # Extract the latitude and longitude from the location object\n",
    "            lat = location.latitude\n",
    "            lon = location.longitude\n",
    "            return lat, lon\n",
    "        else:\n",
    "            print(f\"City '{city_name}' not found.\")\n",
    "            return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error occurred: {e}\")\n",
    "        return None, None\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = open(file=\"data/data_with_tenants.json\", mode=\"r\") \n",
    "\n",
    "data = json.load(data_file)\n",
    "data_file.close()\n",
    "\n",
    "# Take a peek at one data item\n",
    "print(json.dumps(data[4], indent=2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate embeddings for each location and store data in cosmos db container\n",
    "for item in data:\n",
    "    transaction_id = item[\"TransactionID\"]\n",
    "    item['id'] = transaction_id\n",
    "    location = item[\"Location\"]\n",
    "    location_coord = get_city_coordinates(location)\n",
    "    location_embeddings = generate_embeddings(location_coord)\n",
    "    item['locationVector'] = location_embeddings\n",
    "    item['@search.action'] = 'upload'\n",
    "   \n",
    "    print(\"Creating embeddings for transaction:\", transaction_id, end='\\r')\n",
    "    \n",
    "    # Insert the item into the container\n",
    "    container.upsert_item(item)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_std_dev(container, tenant_id):\n",
    "    sql_query = \"SELECT c.Amount FROM c WHERE c.TenantId = @tenant_id\"\n",
    "\n",
    "    # Parameters for the query\n",
    "    parameters = [\n",
    "        {\"name\": \"@tenant_id\", \"value\": tenant_id}\n",
    "    ]\n",
    "    \n",
    "# Execute the query and extract amounts\n",
    "    amounts = []\n",
    "    for item in container.query_items(query=sql_query,parameters=parameters, enable_cross_partition_query=True):\n",
    "        amounts.append(item['Amount'])\n",
    "\n",
    "# Convert the list of amounts to a NumPy array for calculation\n",
    "    amounts_np = np.array(amounts)\n",
    "\n",
    "# Calculate standard deviation\n",
    "    return np.std(amounts_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average_location_vector(container, tenant_id):\n",
    "    # SQL query to get the last 'num_purchases' transactions ordered by timestamp\n",
    "    sql_query = \"\"\"\n",
    "    SELECT c.locationVector\n",
    "    FROM c\n",
    "    WHERE c.TenantId = @tenant_id\n",
    "    ORDER BY c.Timestamp DESC\n",
    "    \"\"\"\n",
    "    \n",
    "    # Parameters for the query\n",
    "    parameters = [\n",
    "        {\"name\": \"@tenant_id\", \"value\": tenant_id}\n",
    "    ]\n",
    "    \n",
    "    # Execute the query to get the location vectors\n",
    "    results = container.query_items(\n",
    "        query=sql_query,\n",
    "        parameters=parameters,\n",
    "        enable_cross_partition_query=True\n",
    "    )\n",
    "    \n",
    "    # Collect the location vectors\n",
    "    vectors = []\n",
    "    for result in results:\n",
    "        vectors.append(result['locationVector'])\n",
    "    \n",
    "    \n",
    "    # If no vectors are found, return None\n",
    "    if not vectors:\n",
    "        return None\n",
    "    \n",
    "    # Convert the list of vectors into a numpy array\n",
    "    vectors_np = np.array(vectors)\n",
    "    \n",
    "    # Calculate the element-wise average of the vectors\n",
    "    avg_vector = np.mean(vectors_np, axis=0)\n",
    "    \n",
    "    return avg_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vector_search( current_location_vector, tenant_id, average_location_vector, amount, num_results=5):\n",
    "\n",
    "    if isinstance(current_location_vector, np.ndarray):\n",
    "        current_location_vector = current_location_vector.tolist()\n",
    "    if isinstance(average_location_vector, np.ndarray):\n",
    "        average_location_vector = average_location_vector.tolist()\n",
    "\n",
    "    sql_query = \"\"\"\n",
    " SELECT \n",
    "        c.TransactionID,\n",
    "        c.Amount, \n",
    "        c.Timestamp, \n",
    "        c.Location, \n",
    "        c.Merchant,\n",
    "        c.TenantId, \n",
    "        VectorDistance(c.locationVector, @current_location_vector) AS LastToCurrDist,\n",
    "        VectorDistance(@current_location_vector, @average_location_vector) AS CurrentToAvgDist\n",
    "    FROM c\n",
    "    WHERE \n",
    "        VectorDistance(c.locationVector, @current_location_vector) > 0.1\n",
    "        AND VectorDistance(@current_location_vector, @average_location_vector) > 0.1\n",
    "        AND c.TenantId = @tenant_id\n",
    "    \"\"\"\n",
    "\n",
    "    # Parameters for the SQL query\n",
    "    parameters = [\n",
    "        {\"name\": \"@num_results\", \"value\": num_results},   \n",
    "        {\"name\": \"@average_location_vector\", \"value\": average_location_vector},  \n",
    "        {\"name\": \"@current_location_vector\", \"value\": current_location_vector},  \n",
    "        {\"name\": \"@amount\", \"value\": amount},  # Transaction amount range filtering\n",
    "        {\"name\": \"@tenant_id\", \"value\": tenant_id},  # Transaction amount range filtering\n",
    "    ]\n",
    "\n",
    "    results = container.query_items(\n",
    "        query=sql_query,\n",
    "        parameters=parameters,\n",
    "        enable_cross_partition_query=True\n",
    "    )\n",
    "\n",
    "    return list(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "def perform_search(tenant_id, city, merchant, amount):\n",
    "\n",
    "    average_location_vector = get_average_location_vector(container, tenant_id)\n",
    "    \n",
    "    # Generate embeddings for the current location\n",
    "    current_location_vector = generate_embeddings(get_city_coordinates(city))\n",
    "    \n",
    "    # Perform vector search\n",
    "    results = vector_search(current_location_vector, tenant_id, average_location_vector, amount, num_results=5)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   TransactionID  Amount            Timestamp  Location   Merchant TenantId  \\\n",
      "0          T3235  282.75  2024-09-15 14:28:38    Boston     Amazon       10   \n",
      "1          T7275  939.29  2024-09-15 14:24:38    Boston    Walmart       10   \n",
      "2          T8014  888.75  2024-09-15 14:23:38  New York        ATM       10   \n",
      "3          T6914   26.98  2024-09-15 13:42:38  New York     Target       10   \n",
      "4          T2355  495.98  2024-09-15 13:47:38  New York    Netflix       10   \n",
      "5          T2039  663.71  2024-09-15 13:40:38  New York    Netflix       10   \n",
      "6          T4982  507.15  2024-09-15 14:22:38    Boston     Target       10   \n",
      "7          T9356  988.69  2024-09-15 14:07:38    Boston     Amazon       10   \n",
      "8          T5194   49.62  2024-09-15 14:34:38    Boston    Netflix       10   \n",
      "9          T2988  427.09  2024-09-15 14:19:38    Boston  Starbucks       10   \n",
      "10         T3852  365.73  2024-09-15 14:17:38  New York        ATM       10   \n",
      "\n",
      "    LastToCurrDist  CurrentToAvgDist  \n",
      "0         0.595425          0.792904  \n",
      "1         0.595425          0.792904  \n",
      "2         0.822421          0.792904  \n",
      "3         0.822421          0.792904  \n",
      "4         0.822421          0.792904  \n",
      "5         0.822421          0.792904  \n",
      "6         0.595425          0.792904  \n",
      "7         0.595425          0.792904  \n",
      "8         0.595425          0.792904  \n",
      "9         0.595425          0.792904  \n",
      "10        0.822421          0.792904  \n"
     ]
    }
   ],
   "source": [
    "tenant_id = \"10\"\n",
    "city = \"New Jersey\"\n",
    "merchant = \"Walmart\"\n",
    "amount = 1000\n",
    "\n",
    "results = perform_search(tenant_id, city, merchant, amount)\n",
    "print(pd.DataFrame(results))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
